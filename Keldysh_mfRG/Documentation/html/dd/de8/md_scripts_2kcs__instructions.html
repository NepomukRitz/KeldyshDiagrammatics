<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>SIAM-Keldysh-mfRG: Introduction to the KCS-Cluster</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../clipboard.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">SIAM-Keldysh-mfRG
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dd/de8/md_scripts_2kcs__instructions.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Introduction to the KCS-Cluster</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Project name for LS vonDelft: <b>pn34vu</b></p>
<h2>Overview</h2>
<ul>
<li>Login node: kcs-login (<code>$ ssh &lt;lrz-ID&gt;@kcs-login.cos.lrz.de</code>)</li>
<li>Need to have an established VPN connection to the MWN (or be physically connected to it).</li>
<li>slurm jobs can only request whole machines -&gt; <b>Always use all 32 cores on each node!</b></li>
<li>150 nodes, 32 cores/node on 2 sockets</li>
<li>memory configurations: 180 GB, 370 GB, 760 GB (2x)</li>
<li>standard queue: runtime: 72h</li>
<li>long-runner queue: runtime: 30 days, only 1 job/user (Slurm: partition kcs_long, see below)</li>
</ul>
<h2>File System</h2>
<ul>
<li>GPFS file system, efficient for large files<ul>
<li>page size 16 MB -&gt; <b>Do not use many small files!</b></li>
<li>quota: 100 TB for the chair</li>
</ul>
</li>
</ul>
<p><br  />
</p>
<ul>
<li>LRZ DSS (data science storage), organized in containers<ul>
<li>LRZ documentation: <a href="https://doku.lrz.de/display/PUBLIC/Data+Science+Storage">https://doku.lrz.de/display/PUBLIC/Data+Science+Storage</a></li>
<li>Web interface for storage management: <a href="https://dssweb.dss.lrz.de">https://dssweb.dss.lrz.de</a> (only accessible for chair admins)</li>
<li>default container 0000<ul>
<li>quota (can be changed via web interface -&gt; ask chair admin): \ 1 TB for chair, 64 GB/user, 65000 files/user</li>
<li>daily backup</li>
<li>path of "home" directory: <code>/dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/\&lt;lrz-ID&gt;</code></li>
</ul>
</li>
<li>can create new containers, some settings cannot be changed afterwards (see LRZ documentation)<ul>
<li>useful for new projects that need a lot of storage (ask chair admin)</li>
</ul>
</li>
<li>share containers via globus (<a href="https://doku.lrz.de/display/PUBLIC/DSS+How+Globus+Data+Transfer+and+Globus+Sharing+for+DSS+works">https://doku.lrz.de/display/PUBLIC/DSS+How+Globus+Data+Transfer+and+Globus+Sharing+for+DSS+works</a>)</li>
</ul>
</li>
</ul>
<h2>Setting up a .bashrc file</h2>
<p>It is highly recommended to set up a <code>.bashrc</code> file to configure shortcuts and load some modules automatically on login.\ In the home-directory entered when logging onto KCS (<code>/dss/dsshome1/lxc09/&lt;lrz-ID&gt;</code>), create a <code>.bashrc</code> file using a command-line text editor like vim or nano (nano has to be loaded first using the module system, see below).\ A good starting point is the following file (comments start with a <code>#</code>):</p>
<div class="fragment"><div class="line"># set up an alias for the &quot;home&quot; directory used for computations</div>
<div class="line">alias kcshome=&quot;cd /dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/&lt;lrz-ID&gt;&quot;</div>
<div class="line"> </div>
<div class="line"># useful to get all information about all files in a given directory in human-readable form</div>
<div class="line">alias ll=&quot;ls -lah&quot;</div>
<div class="line"> </div>
<div class="line"># simplifies navigation through the command-line history</div>
<div class="line">bind &#39;&quot;\e[A&quot;: history-search-backward&#39;</div>
<div class="line">bind &#39;&quot;\e[B&quot;: history-search-forward&#39;</div>
<div class="line"> </div>
<div class="line"># load some modules by default</div>
<div class="line">module load nano                # Beginner-friendly command-line text editor</div>
<div class="line">module load gsl                 # TODO: Better to be included in the compile script!</div>
<div class="line">module load mkl                 # TODO: Do we need this?</div>
<div class="line">module load boost/1.61_icc      # TODO: Warning that this module is scheduled for retirement by end of 2019 (!)</div>
<div class="line"> </div>
<div class="line">module load hdf5/1.8.20-cxx-frt-threadsafe # NOT SUFFICIENT to load in compile script! Needed here as well!</div>
</div><!-- fragment --><p> After creating or modifying the <code>.bashrc</code> file, one has to reload it using <code># source .bashrc</code>. Alternatively, one can log off an log on to KCS again, as the <code>.bashrc</code> file is always automatically loaded upon login.</p>
<h2>Module System</h2>
<p>Grants access to pre-installed packages. Useful commands:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Command   </th><th class="markdownTableHeadNone">Explanation    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>module avail</code>   </td><td class="markdownTableBodyNone">shows available modules    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>module list</code>   </td><td class="markdownTableBodyNone">shows the currently loaded modules    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>module load &lt;module_name&gt;</code>   </td><td class="markdownTableBodyNone">loads the module &lt;module_name&gt;    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>module unload &lt;module_name&gt;</code>   </td><td class="markdownTableBodyNone">unloads the module &lt;module_name&gt;   </td></tr>
</table>
<h2>Cloning the code (to the right place)</h2>
<p>The code should be placed into the "home" directory used for computations, for which the shortcut <code>kcshome</code> was set up in the <code>.bashrc</code> file above. It is then simply a matter of navigating to the "home" directory and cloning the correct git repository: </p><div class="fragment"><div class="line">$ kcshome</div>
<div class="line">$ git clone https://gitlab.physik.uni-muenchen.de/LDAP_ls-vondelft/&lt;project&gt;.git</div>
</div><!-- fragment --><p> It is easiest to clone the git repo via https and not ssh. Otherwise one would have to set up a ssh-key-pair.</p>
<h2>Compiling the code</h2>
<p>Depending on the setup used, there should already be a makefile or a compile script in the code base of the git repository. As of September 2021, the compile script for the Keldysh mfRG code is located at (starting from <code>kcshome</code>) <code>mfrg/Keldysh_mfRG/scripts/compile_kcs.sh</code> and reads</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line">#  environment variable KELDYSH_MFRG needs to point to the &quot;Keldysh_mfRG&quot; directory of the repository:</div>
<div class="line">#  in ~/.bashrc:</div>
<div class="line">#  export KELDYSH_MFRG=&quot;/dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/&lt;lrz-ID&gt;/mfrg/Keldysh_mfRG&quot;</div>
<div class="line"> </div>
<div class="line">module load gcc</div>
<div class="line">module load hdf5/1.8.20-cxx-frt-threadsafe</div>
<div class="line">module load fftw</div>
<div class="line">module load gsl</div>
<div class="line">module load boost/1.61_icc</div>
<div class="line"> </div>
<div class="line">export LANG=C</div>
<div class="line">export LC_ALL=C</div>
<div class="line"> </div>
<div class="line">HDF5=&quot;$HDF5_INC $HDF5_CPP_SHLIB $HDF5_SHLIB $SZIP_LIB -lz&quot;</div>
<div class="line">FFTW=&quot;$FFTW_INC $FFTW_LIB&quot;</div>
<div class="line">GSL=&quot;$GSL_INC $GSL_LIB&quot;</div>
<div class="line">BOOST=&quot;$BOOST_INC -L$BOOST_LIBDIR$&quot;</div>
<div class="line"> </div>
<div class="line">mpiCC -std=c++17 $KELDYSH_MFRG/main.cpp -o $KELDYSH_MFRG/main.o -fopenmp $FFTW $HDF5 $GSL $BOOST</div>
</div><!-- fragment --><p>As one can already tell from this file, before it can be executed, one has to define another shortcut to set the correct absolute path to the directory of the code. To do that, access the <code>.bashrc</code> file via <code>$ nano ~/.bashrc</code> and add the line</p>
<p><code>export KELDYSH_MFRG="/dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/&lt;lrz-ID&gt;/mfrg/Keldysh_mfRG"</code></p>
<p>The compile script can then simply be executed by</p>
<p><code>$ ./mfrg/Keldysh_mfRG/scripts/compile_kcs.sh</code>.</p>
<h2>Submitting jobs</h2>
<p>The job handling of the cluster is organized by SLURM. For basic information on SLURM see <a href="https://www.en.it.physik.uni-muenchen.de/dienste/rechencluster/index.html">https://www.en.it.physik.uni-muenchen.de/dienste/rechencluster/index.html</a>. To submit a job, one needs to provide a corresponding shell script, e.g. by modifying <code>mfrg/Keldysh_mfRG/scripts/batchfile.sh</code> (see official Slurm documentation <a href="https://slurm.schedmd.com/sbatch.html">https://slurm.schedmd.com/sbatch.html</a> for details):</p>
<div class="fragment"><div class="line">#!/bin/bash</div>
<div class="line">#</div>
<div class="line">#SBATCH --job-name=jobname</div>
<div class="line">#SBATCH --mem=2040</div>
<div class="line">#SBATCH --time=2-20:00:00</div>
<div class="line">#SBATCH --mail-type=ALL</div>
<div class="line">#SBATCH --mail-user=&lt;username&gt;@physik.uni-muenchen.de</div>
<div class="line">#SBATCH --chdir=/dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/&lt;lrz-ID&gt;/mfrg/Keldysh_mfRG/</div>
<div class="line">#SBATCH --output=/dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/&lt;lrz-ID&gt;/mfrg/Keldysh_mfRG/runs/jobname.%j.%N.out</div>
<div class="line">#SBATCH --error=/dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/&lt;lrz-ID&gt;/mfrg/Keldysh_mfRG/runs/jobname.%j.%N.err</div>
<div class="line">#SBATCH --nodes=4</div>
<div class="line">#SBATCH --ntasks-per-node=1</div>
<div class="line"> </div>
<div class="line">echo $HOSTNAME</div>
<div class="line">echo $SLURM_ARRAY_JOB_ID</div>
<div class="line">echo $SLURM_NTASKS</div>
<div class="line"> </div>
<div class="line">export OMP_NUM_THREADS=32</div>
<div class="line">mpiexec -n $SLURM_NTASKS ./main.o</div>
</div><!-- fragment --><h3>Description:</h3>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Option   </th><th class="markdownTableHeadNone">Explanation    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>job-name</code>   </td><td class="markdownTableBodyNone">Name of job in slurm queue.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>mem</code>   </td><td class="markdownTableBodyNone">Requested memory (minimum) in MB.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>time</code>   </td><td class="markdownTableBodyNone">Job wall time: after this time, the job will be killed by slurm. Maximum runtime is 3 days.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>mail-type</code>   </td><td class="markdownTableBodyNone">Settings for slurm status emails (see below).    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>chdir</code>   </td><td class="markdownTableBodyNone">Directory in which the batchfile will be executed (=path to executable).    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>output</code>   </td><td class="markdownTableBodyNone">Name of log file. <code>j</code> = job-ID, <code>N</code> = node-ID.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>error</code>   </td><td class="markdownTableBodyNone">Name of error log file.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>nodes</code>   </td><td class="markdownTableBodyNone">Number of (MPI) nodes on which to execute the job.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>ntasks-per-node</code>   </td><td class="markdownTableBodyNone">Number of MPI tasks per node. When using OpenMP, set to 1 (only use MPI for inter-node parallelization).    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>OMP_NUM_THREADS</code>   </td><td class="markdownTableBodyNone">Number of OpenMP threads. Should be equal to the number of available cores per node (=32 on KCS).    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>main.o</code>   </td><td class="markdownTableBodyNone">Job executable.   </td></tr>
</table>
<h3>Optional settings:</h3>
<p><code>#SBATCH --partition=kcs_long</code> : Submit the job to the KCS long-runner queue (wall time &lt; 30 days).</p>
<h3>SLURM status emails:</h3>
<p>If activated, Slurm informs per email when jobs start/finish/fail etc. Deactivate Slurm emails if you are submitting many jobs, and do NOT forward these emails to another email account (see <a href="https://www.en.it.physik.uni-muenchen.de/dienste/rechencluster/index.html">https://www.en.it.physik.uni-muenchen.de/dienste/rechencluster/index.html</a>).</p>
<h2>Useful SLURM commands</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Command   </th><th class="markdownTableHeadNone">Explanation    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>sinfo</code>   </td><td class="markdownTableBodyNone">view information about SLURM nodes and partitions.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>squeue</code>   </td><td class="markdownTableBodyNone">show all information about pending and running jobs    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>squeue -u &lt;lrz-ID&gt;</code>   </td><td class="markdownTableBodyNone">show all information about pending and running jobs of &lt;lrz-ID&gt;    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><code>sbatch batchfile.sh</code>   </td><td class="markdownTableBodyNone">submit a job configured in <code>batchfile.sh</code>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><code>scancel &lt;job-ID&gt;</code>   </td><td class="markdownTableBodyNone">cancel the job &lt;job-ID&gt;   </td></tr>
</table>
<h2>Accessing the data</h2>
<p>Data can be downloaded from KCS to <code>&lt;local-path&gt;</code> on your workstation/laptop using rsync:</p>
<p><code>rsync -auvh &lt;lrz-ID&gt;@kcs-login.cos.lrz.de:/dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/&lt;lrz-ID&gt;/mfrg/Keldysh_mfRG/&lt;path-to-result-file&gt; &lt;local-path&gt;</code></p>
<p>Hint: if you have defined e.g.</p>
<p><code>kcs=&lt;lrz-ID&gt;@kcs-login.cos.lrz.de</code> and</p>
<p><code>kcshome=/dss/dsskcsfs01/pn34vu/pn34vu-dss-0000/&lt;lrz-ID&gt;/mfrg/Keldysh_mfRG</code></p>
<p>in your local .bashrc (on the workstation/laptop), the command simplifies:</p>
<p><code>rsync -auvh $kcs:$kcshome/&lt;path-to-result-file&gt; &lt;local-path&gt;</code>.</p>
<p>(If the command is executed from within the destination directory <code>&lt;local-path&gt;</code>, then simply replace <code>&lt;local-path&gt;</code>=<code>.</code> )</p>
<h2>Running unit tests</h2>
<p>As long as unit test really are just unit test and do not take much time to execute, it should be alright to run them even on the login node. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Thu May 2 2024 15:30:51 for SIAM-Keldysh-mfRG by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0 </li>
  </ul>
</div>
</body>
</html>
